step 0: train loss 10.9873, val loss 10.9915
iter 0: loss 10.9988, time 17059.42ms, mfu -100.00%
/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
iter 10: loss 10.9383, time 648.10ms, mfu 4.33%
iter 20: loss 10.9687, time 649.95ms, mfu 4.33%
iter 30: loss 10.9609, time 653.10ms, mfu 4.32%
iter 40: loss 11.0175, time 648.56ms, mfu 4.32%
iter 50: loss 10.9271, time 669.03ms, mfu 4.31%
iter 60: loss 10.9581, time 1208.22ms, mfu 4.11%
iter 70: loss 10.9767, time 1205.97ms, mfu 3.93%
iter 80: loss 10.9362, time 1206.84ms, mfu 3.77%
iter 90: loss 10.8983, time 1213.23ms, mfu 3.63%
iter 100: loss 10.9167, time 1200.56ms, mfu 3.50%
iter 110: loss 10.9054, time 1208.26ms, mfu 3.38%
iter 120: loss 10.8425, time 1207.60ms, mfu 3.27%
iter 130: loss 10.8177, time 1208.96ms, mfu 3.18%
iter 140: loss 10.8427, time 1212.61ms, mfu 3.09%
iter 150: loss 10.7735, time 1205.43ms, mfu 3.02%
iter 160: loss 10.7793, time 1207.33ms, mfu 2.95%
iter 170: loss 10.7241, time 1213.56ms, mfu 2.88%
iter 180: loss 10.7255, time 1212.04ms, mfu 2.83%
iter 190: loss 10.6967, time 1213.13ms, mfu 2.78%
iter 200: loss 10.6032, time 1208.76ms, mfu 2.73%
iter 210: loss 10.6249, time 1210.18ms, mfu 2.69%
iter 220: loss 10.5839, time 1210.39ms, mfu 2.65%
iter 230: loss 10.6033, time 1209.06ms, mfu 2.62%
iter 240: loss 10.4434, time 1212.18ms, mfu 2.59%
iter 250: loss 10.4556, time 1209.32ms, mfu 2.56%
iter 260: loss 10.4917, time 1216.72ms, mfu 2.54%
iter 270: loss 10.5064, time 1213.39ms, mfu 2.51%
iter 280: loss 10.4196, time 1209.51ms, mfu 2.49%
iter 290: loss 10.3200, time 1196.17ms, mfu 2.48%
iter 300: loss 10.3196, time 1205.22ms, mfu 2.46%
iter 310: loss 10.2570, time 653.58ms, mfu 2.65%
iter 320: loss 10.3594, time 652.38ms, mfu 2.81%
iter 330: loss 10.3601, time 650.88ms, mfu 2.96%
iter 340: loss 10.2693, time 651.98ms, mfu 3.10%
iter 350: loss 10.1480, time 666.94ms, mfu 3.21%
iter 360: loss 10.1686, time 653.26ms, mfu 3.32%
iter 370: loss 10.2327, time 651.62ms, mfu 3.41%
iter 380: loss 10.0938, time 650.99ms, mfu 3.50%
iter 390: loss 10.3647, time 654.02ms, mfu 3.58%
iter 400: loss 9.9766, time 651.97ms, mfu 3.65%
iter 410: loss 10.0075, time 673.99ms, mfu 3.71%
iter 420: loss 10.1643, time 654.45ms, mfu 3.76%
iter 430: loss 10.0842, time 654.63ms, mfu 3.82%
iter 440: loss 9.9612, time 654.78ms, mfu 3.86%
iter 450: loss 9.9051, time 655.27ms, mfu 3.90%
iter 460: loss 9.7534, time 653.98ms, mfu 3.94%
iter 470: loss 10.0837, time 655.28ms, mfu 3.98%
iter 480: loss 9.8836, time 706.87ms, mfu 3.98%
iter 490: loss 9.7236, time 654.14ms, mfu 4.01%
step 500: train loss 9.8061, val loss 9.8088
saving checkpoint to out
iter 500: loss 9.7371, time 17584.06ms, mfu 3.62%
iter 510: loss 9.6910, time 649.98ms, mfu 3.69%
iter 520: loss 9.6950, time 652.84ms, mfu 3.75%
iter 530: loss 9.8415, time 653.94ms, mfu 3.81%
iter 540: loss 9.7591, time 650.97ms, mfu 3.86%
iter 550: loss 9.5987, time 653.40ms, mfu 3.90%
iter 560: loss 9.7654, time 652.76ms, mfu 3.94%
iter 570: loss 9.6740, time 650.82ms, mfu 3.98%
iter 580: loss 9.6010, time 654.34ms, mfu 4.01%
iter 590: loss 9.6504, time 652.59ms, mfu 4.04%
iter 600: loss 9.6139, time 653.33ms, mfu 4.06%
iter 610: loss 9.8069, time 650.90ms, mfu 4.09%
iter 620: loss 9.6718, time 655.60ms, mfu 4.11%
iter 630: loss 9.3958, time 655.97ms, mfu 4.12%
iter 640: loss 9.5451, time 655.03ms, mfu 4.14%
iter 650: loss 9.6730, time 655.14ms, mfu 4.15%
iter 660: loss 9.6071, time 654.36ms, mfu 4.17%
iter 670: loss 9.4843, time 748.10ms, mfu 4.13%
iter 680: loss 9.5949, time 655.74ms, mfu 4.14%
iter 690: loss 9.6912, time 1210.12ms, mfu 3.96%
iter 700: loss 9.4990, time 1210.84ms, mfu 3.79%
iter 710: loss 9.6198, time 1205.22ms, mfu 3.65%
iter 720: loss 9.7239, time 1212.82ms, mfu 3.51%
iter 730: loss 9.4290, time 1208.75ms, mfu 3.39%
iter 740: loss 9.3274, time 1215.28ms, mfu 3.29%
iter 750: loss 9.4791, time 1208.06ms, mfu 3.19%
iter 760: loss 9.5604, time 1211.85ms, mfu 3.10%
iter 770: loss 9.4114, time 1213.08ms, mfu 3.02%
iter 780: loss 9.2968, time 1209.83ms, mfu 2.95%
iter 790: loss 9.3699, time 1209.43ms, mfu 2.89%
iter 800: loss 9.6832, time 1210.36ms, mfu 2.83%
iter 810: loss 9.9360, time 1209.33ms, mfu 2.78%
iter 820: loss 9.4969, time 1213.03ms, mfu 2.73%
iter 830: loss 9.3497, time 1210.06ms, mfu 2.69%
iter 840: loss 9.9226, time 1205.89ms, mfu 2.66%
iter 850: loss 9.6355, time 1205.53ms, mfu 2.62%
iter 860: loss 9.3995, time 1209.10ms, mfu 2.59%
iter 870: loss 9.3065, time 1213.53ms, mfu 2.56%
iter 880: loss 9.2841, time 1203.04ms, mfu 2.54%
iter 890: loss 9.1686, time 1209.02ms, mfu 2.52%
iter 900: loss 9.3929, time 1212.22ms, mfu 2.50%
iter 910: loss 9.5673, time 1205.62ms, mfu 2.48%
iter 920: loss 9.1872, time 1208.51ms, mfu 2.47%
iter 930: loss 9.1050, time 1214.12ms, mfu 2.45%
iter 940: loss 9.1210, time 649.38ms, mfu 2.64%
iter 950: loss 9.0243, time 651.78ms, mfu 2.80%
iter 960: loss 9.4070, time 650.55ms, mfu 2.95%
iter 970: loss 9.0979, time 651.86ms, mfu 3.09%
iter 980: loss 9.2873, time 653.09ms, mfu 3.21%
iter 990: loss 9.2325, time 651.43ms, mfu 3.32%
step 1000: train loss 9.1918, val loss 9.2082
saving checkpoint to out
iter 1000: loss 8.9604, time 17731.99ms, mfu 3.00%
iter 1010: loss 9.2625, time 649.97ms, mfu 3.13%
iter 1020: loss 9.2913, time 648.73ms, mfu 3.25%
iter 1030: loss 9.3506, time 653.86ms, mfu 3.36%
iter 1040: loss 9.0697, time 652.81ms, mfu 3.45%
iter 1050: loss 9.1515, time 652.38ms, mfu 3.54%
iter 1060: loss 9.2387, time 653.52ms, mfu 3.61%
iter 1070: loss 9.0182, time 653.84ms, mfu 3.68%
iter 1080: loss 9.1589, time 651.60ms, mfu 3.74%
iter 1090: loss 9.1062, time 651.54ms, mfu 3.80%
iter 1100: loss 9.2549, time 652.63ms, mfu 3.85%
iter 1110: loss 9.1377, time 651.94ms, mfu 3.89%
iter 1120: loss 9.1074, time 655.28ms, mfu 3.93%
iter 1130: loss 8.9986, time 652.48ms, mfu 3.97%
iter 1140: loss 9.3819, time 653.80ms, mfu 4.00%
iter 1150: loss 9.0035, time 651.15ms, mfu 4.03%
iter 1160: loss 9.0999, time 651.83ms, mfu 4.06%
iter 1170: loss 9.1825, time 651.41ms, mfu 4.08%
iter 1180: loss 8.9863, time 653.26ms, mfu 4.11%
iter 1190: loss 9.0719, time 847.15ms, mfu 4.03%
iter 1200: loss 9.1601, time 652.05ms, mfu 4.05%
iter 1210: loss 9.0162, time 652.49ms, mfu 4.08%
iter 1220: loss 8.9643, time 650.59ms, mfu 4.10%
iter 1230: loss 9.1142, time 653.39ms, mfu 4.12%
iter 1240: loss 8.9195, time 653.20ms, mfu 4.14%
iter 1250: loss 8.8135, time 653.79ms, mfu 4.15%
iter 1260: loss 8.9144, time 653.58ms, mfu 4.17%
iter 1270: loss 8.9523, time 654.01ms, mfu 4.18%
iter 1280: loss 9.0262, time 652.37ms, mfu 4.19%
iter 1290: loss 8.8939, time 653.11ms, mfu 4.20%
iter 1300: loss 8.9118, time 650.93ms, mfu 4.21%
iter 1310: loss 8.8568, time 654.03ms, mfu 4.22%
iter 1320: loss 8.9817, time 652.69ms, mfu 4.23%
iter 1330: loss 9.0233, time 650.53ms, mfu 4.24%
iter 1340: loss 9.0753, time 651.50ms, mfu 4.24%
iter 1350: loss 8.8813, time 806.39ms, mfu 4.17%
iter 1360: loss 8.9938, time 650.78ms, mfu 4.18%
iter 1370: loss 8.9014, time 652.11ms, mfu 4.19%
iter 1380: loss 8.7911, time 651.91ms, mfu 4.20%
iter 1390: loss 9.0953, time 651.64ms, mfu 4.21%
iter 1400: loss 9.0030, time 652.99ms, mfu 4.22%
iter 1410: loss 8.8376, time 652.26ms, mfu 4.23%
iter 1420: loss 8.6734, time 651.52ms, mfu 4.24%
iter 1430: loss 8.9184, time 651.02ms, mfu 4.25%
iter 1440: loss 8.7864, time 652.80ms, mfu 4.25%
iter 1450: loss 9.1125, time 652.84ms, mfu 4.26%
iter 1460: loss 8.8308, time 652.42ms, mfu 4.26%
iter 1470: loss 8.9449, time 651.08ms, mfu 4.26%
iter 1480: loss 9.1413, time 650.86ms, mfu 4.27%
iter 1490: loss 8.7502, time 652.54ms, mfu 4.27%
step 1500: train loss 8.8716, val loss 8.8842
saving checkpoint to out
iter 1500: loss 8.6948, time 17780.17ms, mfu 3.86%
iter 1510: loss 8.7864, time 648.63ms, mfu 3.91%
iter 1520: loss 8.8825, time 648.93ms, mfu 3.95%
iter 1530: loss 8.6531, time 652.15ms, mfu 3.98%
iter 1540: loss 8.8874, time 654.70ms, mfu 4.01%
iter 1550: loss 8.7872, time 655.24ms, mfu 4.04%
iter 1560: loss 8.7672, time 653.06ms, mfu 4.07%
iter 1570: loss 9.0576, time 652.81ms, mfu 4.09%
iter 1580: loss 8.8904, time 652.60ms, mfu 4.11%
iter 1590: loss 8.7465, time 652.44ms, mfu 4.13%
iter 1600: loss 8.7439, time 653.48ms, mfu 4.15%
iter 1610: loss 8.8069, time 653.31ms, mfu 4.16%
iter 1620: loss 8.7334, time 653.22ms, mfu 4.17%
iter 1630: loss 8.5268, time 650.88ms, mfu 4.19%
iter 1640: loss 8.5140, time 652.59ms, mfu 4.20%
iter 1650: loss 8.9007, time 653.97ms, mfu 4.21%
iter 1660: loss 9.0239, time 651.78ms, mfu 4.22%
iter 1670: loss 8.5647, time 654.18ms, mfu 4.22%
iter 1680: loss 8.7749, time 651.45ms, mfu 4.23%
iter 1690: loss 9.1456, time 653.46ms, mfu 4.24%
iter 1700: loss 8.7914, time 653.74ms, mfu 4.24%
iter 1710: loss 8.9307, time 651.46ms, mfu 4.25%
iter 1720: loss 8.8487, time 654.65ms, mfu 4.25%
iter 1730: loss 8.5771, time 727.22ms, mfu 4.21%
iter 1740: loss 8.9685, time 1201.15ms, mfu 4.03%
iter 1750: loss 8.9833, time 1210.81ms, mfu 3.86%
iter 1760: loss 8.8270, time 1213.86ms, mfu 3.70%
iter 1770: loss 8.8833, time 1215.60ms, mfu 3.56%
iter 1780: loss 8.5838, time 1215.50ms, mfu 3.44%
iter 1790: loss 8.3950, time 1209.39ms, mfu 3.32%
iter 1800: loss 8.7427, time 1205.92ms, mfu 3.22%
iter 1810: loss 8.6681, time 1208.32ms, mfu 3.13%
iter 1820: loss 8.6369, time 1212.88ms, mfu 3.05%
iter 1830: loss 8.7052, time 1214.66ms, mfu 2.98%
iter 1840: loss 8.4478, time 1203.37ms, mfu 2.91%
iter 1850: loss 8.7689, time 1210.41ms, mfu 2.85%
iter 1860: loss 8.5126, time 1210.07ms, mfu 2.80%
iter 1870: loss 8.9800, time 1208.09ms, mfu 2.75%
iter 1880: loss 8.6367, time 1206.70ms, mfu 2.71%
iter 1890: loss 8.7872, time 1213.20ms, mfu 2.67%
iter 1900: loss 8.5194, time 1215.24ms, mfu 2.63%
iter 1910: loss 8.5105, time 1207.19ms, mfu 2.60%
iter 1920: loss 8.4772, time 1214.38ms, mfu 2.57%
iter 1930: loss 8.4548, time 1209.61ms, mfu 2.55%
iter 1940: loss 8.5129, time 1213.33ms, mfu 2.52%
iter 1950: loss 8.7633, time 1213.14ms, mfu 2.50%
iter 1960: loss 8.4358, time 1209.65ms, mfu 2.48%
iter 1970: loss 9.1218, time 1213.38ms, mfu 2.47%
iter 1980: loss 8.8294, time 651.86ms, mfu 2.65%
iter 1990: loss 8.4401, time 650.71ms, mfu 2.82%
step 2000: train loss 8.6658, val loss 8.6684
saving checkpoint to out
iter 2000: loss 8.7049, time 17888.12ms, mfu 2.55%
iter 2010: loss 8.2645, time 650.91ms, mfu 2.73%
iter 2020: loss 9.0697, time 650.82ms, mfu 2.89%
iter 2030: loss 8.6858, time 649.96ms, mfu 3.03%
iter 2040: loss 8.2568, time 651.81ms, mfu 3.16%
iter 2050: loss 8.6913, time 652.77ms, mfu 3.27%
iter 2060: loss 8.6534, time 652.09ms, mfu 3.37%
iter 2070: loss 8.9391, time 649.37ms, mfu 3.47%
iter 2080: loss 8.9170, time 651.20ms, mfu 3.55%
iter 2090: loss 8.3990, time 651.38ms, mfu 3.63%
iter 2100: loss 8.7086, time 653.64ms, mfu 3.69%
iter 2110: loss 8.4856, time 651.22ms, mfu 3.76%
iter 2120: loss 8.5354, time 652.39ms, mfu 3.81%
iter 2130: loss 8.6383, time 652.60ms, mfu 3.86%
iter 2140: loss 8.6992, time 651.19ms, mfu 3.90%
iter 2150: loss 9.0264, time 653.47ms, mfu 3.94%
iter 2160: loss 8.4129, time 651.76ms, mfu 3.98%
iter 2170: loss 8.6983, time 652.55ms, mfu 4.01%
iter 2180: loss 8.5912, time 651.96ms, mfu 4.04%
iter 2190: loss 8.5652, time 652.82ms, mfu 4.07%
iter 2200: loss 8.4412, time 654.42ms, mfu 4.09%
iter 2210: loss 8.3612, time 654.54ms, mfu 4.11%
iter 2220: loss 8.5589, time 653.95ms, mfu 4.13%
iter 2230: loss 8.6344, time 651.88ms, mfu 4.14%
iter 2240: loss 8.6931, time 655.80ms, mfu 4.16%
iter 2250: loss 8.3525, time 657.25ms, mfu 4.17%
iter 2260: loss 8.4377, time 653.89ms, mfu 4.18%
iter 2270: loss 8.2224, time 651.09ms, mfu 4.19%
iter 2280: loss 8.5467, time 651.46ms, mfu 4.20%
iter 2290: loss 8.5601, time 653.66ms, mfu 4.21%
iter 2300: loss 8.2622, time 653.97ms, mfu 4.22%
iter 2310: loss 8.6133, time 653.27ms, mfu 4.23%
iter 2320: loss 8.6921, time 655.24ms, mfu 4.23%
iter 2330: loss 8.2668, time 651.72ms, mfu 4.24%
iter 2340: loss 9.6696, time 654.41ms, mfu 4.25%
iter 2350: loss 8.5491, time 650.77ms, mfu 4.25%
iter 2360: loss 8.9113, time 653.69ms, mfu 4.26%
iter 2370: loss 9.1017, time 654.09ms, mfu 4.26%
iter 2380: loss 8.7150, time 652.93ms, mfu 4.26%
iter 2390: loss 8.3778, time 656.90ms, mfu 4.26%
iter 2400: loss 8.3895, time 652.66ms, mfu 4.27%
iter 2410: loss 8.5401, time 656.65ms, mfu 4.27%
iter 2420: loss 8.5459, time 653.36ms, mfu 4.27%
iter 2430: loss 8.2943, time 655.38ms, mfu 4.27%
iter 2440: loss 9.2650, time 654.86ms, mfu 4.27%
iter 2450: loss 8.5235, time 652.38ms, mfu 4.28%
iter 2460: loss 7.9384, time 654.79ms, mfu 4.28%
iter 2470: loss 8.1911, time 652.80ms, mfu 4.28%
iter 2480: loss 8.7037, time 652.94ms, mfu 4.28%
iter 2490: loss 8.2711, time 655.88ms, mfu 4.28%
step 2500: train loss 8.4651, val loss 8.5155
saving checkpoint to out
iter 2500: loss 8.6116, time 17764.91ms, mfu 3.87%
iter 2510: loss 8.3250, time 649.49ms, mfu 3.91%
iter 2520: loss 8.3715, time 653.60ms, mfu 3.95%
iter 2530: loss 8.3901, time 652.57ms, mfu 3.99%
iter 2540: loss 8.3174, time 653.61ms, mfu 4.02%
iter 2550: loss 8.3117, time 651.27ms, mfu 4.05%
iter 2560: loss 8.4400, time 652.27ms, mfu 4.07%
iter 2570: loss 8.6444, time 652.85ms, mfu 4.09%
iter 2580: loss 8.9894, time 654.08ms, mfu 4.11%
iter 2590: loss 8.9354, time 654.62ms, mfu 4.13%
iter 2600: loss 8.0516, time 653.89ms, mfu 4.15%
iter 2610: loss 8.4358, time 655.40ms, mfu 4.16%
iter 2620: loss 9.0789, time 652.22ms, mfu 4.17%
iter 2630: loss 8.4686, time 655.03ms, mfu 4.18%
iter 2640: loss 8.0620, time 656.89ms, mfu 4.19%
iter 2650: loss 8.1832, time 652.64ms, mfu 4.20%
iter 2660: loss 8.3581, time 651.87ms, mfu 4.21%
iter 2670: loss 8.2552, time 654.20ms, mfu 4.22%
iter 2680: loss 8.4398, time 651.76ms, mfu 4.23%
iter 2690: loss 9.3778, time 656.75ms, mfu 4.23%
iter 2700: loss 8.5469, time 652.67ms, mfu 4.24%
iter 2710: loss 8.5149, time 655.86ms, mfu 4.24%
iter 2720: loss 8.5580, time 652.99ms, mfu 4.25%
iter 2730: loss 8.2816, time 655.00ms, mfu 4.25%
iter 2740: loss 8.3696, time 654.22ms, mfu 4.26%
iter 2750: loss 8.5616, time 651.96ms, mfu 4.26%
iter 2760: loss 8.4404, time 652.57ms, mfu 4.26%
iter 2770: loss 7.9868, time 652.37ms, mfu 4.27%
iter 2780: loss 8.4183, time 657.16ms, mfu 4.27%
iter 2790: loss 8.2335, time 652.79ms, mfu 4.27%
iter 2800: loss 8.4940, time 655.41ms, mfu 4.27%
Traceback (most recent call last):
  File "train.py", line 351, in <module>
    logits, loss = model(X, Y)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt