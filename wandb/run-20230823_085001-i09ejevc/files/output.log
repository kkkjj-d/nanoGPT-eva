step 0: train loss 10.9873, val loss 10.9915
iter 0: loss 10.9988, time 17925.32ms, mfu -100.00%
/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
iter 10: loss 10.9388, time 650.34ms, mfu 4.31%
iter 20: loss 10.9711, time 646.05ms, mfu 4.32%
iter 30: loss 10.9663, time 651.12ms, mfu 4.32%
iter 40: loss 11.0276, time 646.98ms, mfu 4.32%
iter 50: loss 10.9447, time 649.67ms, mfu 4.32%
iter 60: loss 10.9813, time 652.04ms, mfu 4.32%
iter 70: loss 11.0059, time 651.23ms, mfu 4.32%
iter 80: loss 10.9749, time 651.65ms, mfu 4.31%
iter 90: loss 10.9535, time 653.42ms, mfu 4.31%
iter 100: loss 10.9764, time 653.37ms, mfu 4.31%
iter 110: loss 10.9816, time 652.50ms, mfu 4.31%
iter 120: loss 10.9411, time 653.76ms, mfu 4.31%
iter 130: loss 10.9151, time 653.34ms, mfu 4.31%
iter 140: loss 10.9690, time 653.69ms, mfu 4.30%
iter 150: loss 10.9176, time 662.00ms, mfu 4.30%
iter 160: loss 10.9506, time 653.97ms, mfu 4.30%
iter 170: loss 10.9094, time 654.88ms, mfu 4.30%
iter 180: loss 10.9119, time 655.94ms, mfu 4.29%
iter 190: loss 10.9093, time 655.02ms, mfu 4.29%
iter 200: loss 10.8862, time 685.54ms, mfu 4.27%
iter 210: loss 10.9023, time 653.53ms, mfu 4.27%
iter 220: loss 10.8873, time 680.46ms, mfu 4.26%
iter 230: loss 10.8824, time 654.20ms, mfu 4.26%
iter 240: loss 10.8311, time 654.76ms, mfu 4.26%
iter 250: loss 10.8188, time 655.49ms, mfu 4.27%
iter 260: loss 10.8332, time 655.14ms, mfu 4.27%
iter 270: loss 10.8326, time 655.50ms, mfu 4.27%
iter 280: loss 10.8309, time 655.61ms, mfu 4.27%
iter 290: loss 10.7862, time 657.71ms, mfu 4.27%
iter 300: loss 10.7762, time 655.47ms, mfu 4.27%
iter 310: loss 10.7699, time 655.82ms, mfu 4.27%
iter 320: loss 10.8005, time 652.84ms, mfu 4.27%
iter 330: loss 10.7652, time 653.52ms, mfu 4.28%
iter 340: loss 10.7620, time 654.69ms, mfu 4.28%
iter 350: loss 10.7073, time 684.48ms, mfu 4.26%
iter 360: loss 10.7149, time 654.72ms, mfu 4.26%
iter 370: loss 10.7325, time 655.49ms, mfu 4.26%
iter 380: loss 10.6893, time 654.57ms, mfu 4.27%
iter 390: loss 10.7502, time 655.13ms, mfu 4.27%
iter 400: loss 10.6389, time 655.31ms, mfu 4.27%
iter 410: loss 10.6429, time 727.56ms, mfu 4.23%
iter 420: loss 10.6919, time 654.59ms, mfu 4.23%
iter 430: loss 10.6320, time 655.46ms, mfu 4.24%
iter 440: loss 10.6051, time 654.45ms, mfu 4.24%
iter 450: loss 10.5859, time 653.12ms, mfu 4.25%
iter 460: loss 10.5312, time 655.46ms, mfu 4.25%
iter 470: loss 10.6361, time 654.63ms, mfu 4.25%
iter 480: loss 10.5582, time 680.18ms, mfu 4.24%
iter 490: loss 10.5134, time 655.28ms, mfu 4.25%
iter 500: loss 10.5340, time 655.57ms, mfu 4.25%
iter 510: loss 10.4930, time 652.07ms, mfu 4.25%
iter 520: loss 10.5448, time 653.87ms, mfu 4.26%
iter 530: loss 10.4884, time 655.66ms, mfu 4.26%
iter 540: loss 10.4435, time 701.40ms, mfu 4.23%
iter 550: loss 10.4256, time 653.67ms, mfu 4.24%
iter 560: loss 10.4004, time 931.15ms, mfu 4.12%
iter 570: loss 10.3868, time 1198.90ms, mfu 3.94%
iter 580: loss 10.3380, time 1207.39ms, mfu 3.78%
iter 590: loss 10.4019, time 1212.59ms, mfu 3.63%
iter 600: loss 10.3459, time 1206.89ms, mfu 3.50%
iter 610: loss 10.2394, time 1213.54ms, mfu 3.38%
iter 620: loss 10.3578, time 1196.11ms, mfu 3.28%
iter 630: loss 10.3001, time 1211.14ms, mfu 3.18%
iter 640: loss 10.2373, time 1203.20ms, mfu 3.10%
iter 650: loss 10.2700, time 1213.62ms, mfu 3.02%
iter 660: loss 10.2374, time 1215.54ms, mfu 2.95%
iter 670: loss 10.3509, time 1212.74ms, mfu 2.88%
iter 680: loss 10.2753, time 1211.87ms, mfu 2.83%
iter 690: loss 10.0748, time 1213.03ms, mfu 2.78%
iter 700: loss 10.1827, time 1216.85ms, mfu 2.73%
iter 710: loss 10.2714, time 1209.51ms, mfu 2.69%
iter 720: loss 10.1796, time 1211.72ms, mfu 2.65%
iter 730: loss 10.1113, time 1207.69ms, mfu 2.62%
iter 740: loss 10.1658, time 1211.10ms, mfu 2.59%
iter 750: loss 10.2250, time 1209.28ms, mfu 2.56%
iter 760: loss 10.0983, time 1215.69ms, mfu 2.54%
iter 770: loss 10.1990, time 1213.78ms, mfu 2.51%
iter 780: loss 10.2185, time 1214.36ms, mfu 2.49%
iter 790: loss 10.0272, time 1209.79ms, mfu 2.48%
iter 800: loss 9.9534, time 1216.60ms, mfu 2.46%
iter 810: loss 10.0642, time 652.49ms, mfu 2.64%
iter 820: loss 10.1084, time 652.10ms, mfu 2.81%
iter 830: loss 9.9996, time 650.32ms, mfu 2.96%
iter 840: loss 9.9358, time 651.41ms, mfu 3.09%
iter 850: loss 9.9500, time 655.73ms, mfu 3.21%
iter 860: loss 10.1364, time 653.51ms, mfu 3.32%
iter 870: loss 10.2898, time 653.46ms, mfu 3.42%
iter 880: loss 10.0346, time 650.88ms, mfu 3.51%
iter 890: loss 9.9191, time 655.63ms, mfu 3.58%
iter 900: loss 10.2773, time 654.04ms, mfu 3.65%
iter 910: loss 10.0914, time 654.18ms, mfu 3.72%
iter 920: loss 9.9516, time 654.49ms, mfu 3.77%
iter 930: loss 9.8437, time 654.03ms, mfu 3.83%
iter 940: loss 9.8734, time 654.38ms, mfu 3.87%
iter 950: loss 9.7570, time 654.95ms, mfu 3.91%
iter 960: loss 9.9068, time 653.42ms, mfu 3.95%
iter 970: loss 10.0272, time 655.22ms, mfu 3.98%
iter 980: loss 9.7855, time 655.84ms, mfu 4.01%
iter 990: loss 9.7100, time 653.95ms, mfu 4.04%
step 1000: train loss 9.7961, val loss 9.7946
saving checkpoint to out
iter 1000: loss 9.7928, time 17809.65ms, mfu 3.65%
iter 1010: loss 9.8356, time 654.45ms, mfu 3.72%
iter 1020: loss 9.7042, time 653.75ms, mfu 3.77%
iter 1030: loss 9.9513, time 654.02ms, mfu 3.83%
iter 1040: loss 9.5381, time 653.60ms, mfu 3.87%
iter 1050: loss 9.7219, time 653.44ms, mfu 3.91%
iter 1060: loss 9.5957, time 653.03ms, mfu 3.95%
iter 1070: loss 9.7796, time 653.22ms, mfu 3.99%
iter 1080: loss 9.7820, time 651.90ms, mfu 4.02%
Error in sys.excepthook:
Traceback (most recent call last):
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/linecache.py", line 137, in updatecache
    lines = fp.readlines()
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/codecs.py", line 319, in decode
    def decode(self, input, final=False):
KeyboardInterrupt
Original exception was:
Traceback (most recent call last):
  File "train.py", line 345, in <module>
    logits, loss = model(X, Y)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1008, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 969, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yxdong/nano-gpt-test/nanoGPT-eva/model.py", line 181, in forward
    x = block(x)
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yxdong/nano-gpt-test/nanoGPT-eva/model.py", line 104, in forward
    x = x + self.attn(self.ln_1(x))
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yxdong/nano-gpt-test/nanoGPT-eva/model.py", line 75, in forward
    y = self.resid_dropout(self.c_proj(y))
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1137, in _call_impl
    result = hook(self, input)
  File "/home/yxdong/nano-gpt-test/nanoGPT-eva/eva.py", line 96, in _forward_hook_event
    if self.backend.size() > 1:
  File "/home/yxdong/nano-gpt-test/nanoGPT-eva/eva_backend.py", line 120, in size
    return dist.get_world_size()
  File "/home/yxdong/anaconda3/envs/dyx-py38/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 851, in get_world_size
    def get_world_size(group=None):
KeyboardInterrupt